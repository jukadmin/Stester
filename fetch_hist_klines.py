from __future__ import annotations
import time
from datetime import datetime, timezone
from typing import List, Dict, Tuple
import pandas as pd
import requests
from pymongo import MongoClient, ASCENDING, UpdateOne
from pymongo.collection import Collection


"""
–°–∫–∞—á–∏–≤–∞–µ—Ç –º–∏–Ω—É—Ç–Ω—ã–µ —Ñ—å—é—á–µ—Ä—Å‚Äë—Å–≤–µ—á–∏ —Å¬†Binance, —Å–∫–ª–∞–¥—ã–≤–∞–µ—Ç –≤¬†MongoDB,
–ø—Ä–∏ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç CSV.

‚úì  –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–µ—Ç¬†–ª–∏ —É–∂–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤¬†Mongo ‚Üí¬†–µ—Å–ª–∏ –µ—Å—Ç—å, —Å—Ä–∞–∑—É CSV
‚úì  –î–ª—è –∫–∞–∂–¥–æ–≥–æ 2‚Äë—á–∞—Å–æ–≤–æ–≥–æ —á–∞–Ω–∫–∞ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ
‚úì  –ß—Ç–µ–Ω–∏–µ –∏–∑¬†Mongo –≤¬†—ç–∫—Å–ø–æ—Ä—Ç¬†‚Äî –ø–æ—Ç–æ–∫–æ–≤–æ (batch_size), –±–µ–∑ list(find(...))
‚úì  –ó–∞–≤–µ—Ä—à–∞–µ—Ç —Å–µ—Å—Å–∏—é MongoClient (client.close()) –≤–æ –∏–∑–±–µ–∂–∞–Ω–∏–µ —É—Ç–µ—á–µ–∫
‚úì  –°–æ–≤–º–µ—Å—Ç–∏–º–æ —Å¬†Python¬†3.13+
"""


# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
START_DATETIME = "2025-01-01 00:00:00"
END_DATETIME = "2025-07-05 00:00:00"
INTERVAL = "1m"
CHUNK_HOURS = 24
LIMIT = 1500
MONGO_URI = "mongodb://localhost:27017"

BINANCE_FAPI_URL = "https://fapi.binance.com/fapi/v1/klines"


# --------------------------------------------------------------------------- #
#                               MongoDB helpers                               #
# --------------------------------------------------------------------------- #


def mongo_client_and_coll(symbol: str, db_name: str) -> Tuple[MongoClient, Collection]:
    client = MongoClient(MONGO_URI)
    coll = client[db_name][f"hist_klines_1m_{symbol.lower()}"]
    if "timestamp_1" not in coll.index_information():
        coll.create_index([("timestamp", ASCENDING)], unique=True)
    return client, coll


def has_full_range(coll, start_ts: int, end_ts: int) -> bool:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –≤¬†–∫–æ–ª–ª–µ–∫—Ü–∏–∏ –µ—Å—Ç—å —Ä–æ–≤–Ω–æ
    (end_ts - start_ts) //¬†60_000 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å¬†timestamp¬†‚àà¬†[start, end)
    """
    expected = (end_ts - start_ts) // 60_000
    actual = coll.count_documents({"timestamp": {"$gte": start_ts, "$lt": end_ts}})
    return actual == expected


# --------------------------------------------------------------------------- #
#                               Binance helpers                               #
# --------------------------------------------------------------------------- #


def fetch_klines(symbol: str, start_ts_ms: int, end_ts_ms: int) -> List[List]:
    resp = requests.get(
        BINANCE_FAPI_URL,
        params={
            "symbol": symbol.upper(),
            "interval": INTERVAL,
            "startTime": start_ts_ms,
            "endTime": end_ts_ms,
            "limit": LIMIT,
        },
        timeout=10,
    )
    resp.raise_for_status()
    return resp.json()


def normalize(raw: List[List]) -> List[Dict]:
    return [
        {
            "timestamp": int(k[0]),
            "open": float(k[1]),
            "high": float(k[2]),
            "low": float(k[3]),
            "close": float(k[4]),
            "volume": float(k[5]),
        }
        for k in raw
    ]


# --------------------------------------------------------------------------- #
#                               CSV export                                    #
# --------------------------------------------------------------------------- #


def export_to_csv(coll, start_ts: int, end_ts: int, output_file: str) -> None:
    """
    –ü–æ—Ç–æ–∫–æ–≤–æ —á–∏—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Mongo –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤¬†CSV.
    """
    cursor = coll.find(
        {"timestamp": {"$gte": start_ts, "$lt": end_ts}},
        {"_id": 0, "timestamp": 1, "open": 1, "high": 1, "low": 1, "close": 1, "volume": 1},
        batch_size=1_000,
       ) # no_cursor_timeout=True

    rows: list[dict] = []
    for doc in cursor:
        rows.append(doc)
    cursor.close()

    if not rows:
        print("‚ö† CSV –Ω–µ —Å–æ–∑–¥–∞–Ω: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö.")
        return

    df = pd.DataFrame(rows)
    df["Date"] = pd.to_datetime(df["timestamp"], unit="ms")
    df = df.rename(
        columns={
            "open": "Open",
            "high": "High",
            "low": "Low",
            "close": "Close",
            "volume": "Volume",
        }
    )
    df = df[["Date", "Open", "High", "Low", "Close", "Volume"]]
    df["Date"] = df["Date"].dt.strftime("%Y-%m-%d %H:%M:%S")
    df.to_csv(output_file, index=False)
    print(f"üìÑ CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")


# --------------------------------------------------------------------------- #
#                               Main logic                                    #
# --------------------------------------------------------------------------- #


def get_klines(symbol: str, database_name: str) -> bool:
    start_dt = datetime.strptime(START_DATETIME, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
    end_dt = datetime.strptime(END_DATETIME, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
    start_ts = int(start_dt.timestamp() * 1000)
    end_ts = int(end_dt.timestamp() * 1000)

    client, coll = mongo_client_and_coll(symbol, database_name)

    try:
        # ---------- —à–∞–≥ 1. –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ ------------------------
        if has_full_range(coll, start_ts, end_ts):
            print("‚úÖ –î–∞–Ω–Ω—ã–µ —É–∂–µ –≤ Mongo. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ.")
            csv_name = f"{symbol.upper()}_{INTERVAL}_{START_DATETIME[:10]}.csv"
            export_to_csv(coll, start_ts, end_ts, csv_name)
            return True

        # ---------- —à–∞–≥ 2. —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —á–∞–Ω–∫–∞–º–∏ ------------------------------
        print(
            f"[{symbol}] –ó–∞–≥—Ä—É–∑–∫–∞ —Å {start_dt:%Y-%m-%d %H:%M:%S} UTC "
            f"–ø–æ {end_dt:%Y-%m-%d %H:%M:%S} UTC, —à–∞–≥ {CHUNK_HOURS}—á"
        )

        step_ms = CHUNK_HOURS * 60 * 60 * 1000
        total_upserts = 0

        for chunk_start in range(start_ts, end_ts, step_ms):
            chunk_end_exc = min(chunk_start + step_ms, end_ts)  # [start, end)
            dt_start = datetime.fromtimestamp(chunk_start / 1000, tz=timezone.utc)
            dt_end = datetime.fromtimestamp((chunk_end_exc - 1) / 1000, tz=timezone.utc)
            print(f"  ‚Üí {dt_start:%Y-%m-%d %H:%M}‚Äì{dt_end:%Y-%m-%d %H:%M}", end="")

            if has_full_range(coll, chunk_start, chunk_end_exc):
                print(" (—É–∂–µ –µ—Å—Ç—å, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º)")
                continue

            try:
                raw = fetch_klines(symbol, chunk_start, chunk_end_exc - 1)
            except Exception as e:
                print(f"\n    ‚ö† –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
                return False

            docs = normalize(raw)
            if not docs:
                print(" ‚Äî –ø—É—Å—Ç–æ")
                continue

            # bulk_write –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è round‚Äëtrip
            requests_bulk = [
                UpdateOne({"timestamp": d["timestamp"]}, {"$set": d}, upsert=True) for d in docs
            ]
            result = coll.bulk_write(requests_bulk, ordered=False)
            upserted = result.upserted_count + result.modified_count
            total_upserts += upserted
            print(f" ‚Äî upsert {upserted}")

            time.sleep(0.25)  # —á—É—Ç—å –±—ã—Å—Ç—Ä–µ–µ

        # ---------- —à–∞–≥ 3. —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ CSV ------------------------
        print(f"‚úÖ –í—Å–µ–≥–æ –≤—Å—Ç–∞–≤–ª–µ–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ: {total_upserts}")
        if has_full_range(coll, start_ts, end_ts):
            csv_name = f"{symbol.upper()}_{INTERVAL}_{START_DATETIME[:10]}_{END_DATETIME[:10]}.csv"
            export_to_csv(coll, start_ts, end_ts, csv_name)
        else:
            print("‚ùå CSV –Ω–µ —Å–æ–∑–¥–∞–Ω: –¥–∏–∞–ø–∞–∑–æ–Ω –∑–∞–ø–æ–ª–Ω–µ–Ω –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é.")
        return True
    finally:
        client.close()


# --------------------------------------------------------------------------- #
#                               Entry point                                   #
# --------------------------------------------------------------------------- #

if __name__ == "__main__":
    get_klines("DOTUSDT", "cbxbot_db")
